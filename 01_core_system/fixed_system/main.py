#!/usr/bin/env python3
"""
Sistema AutoGen 1000 - Vers√£o Otimizada
Compat√≠vel com pyautogen 0.2.18
"""

import os
import sys
import logging
import argparse
from pathlib import Path
from typing import Dict, Any, Optional

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# Importa√ß√µes do AutoGen
try:
    import autogen
    from autogen import AssistantAgent, UserProxyAgent, config_list_from_json
    logger.info(f"‚úÖ AutoGen {autogen.__version__} carregado com sucesso!")
except ImportError as e:
    logger.error(f"‚ùå Erro ao importar AutoGen: {e}")
    sys.exit(1)

class AutoGenSystem1000:
    """Sistema AutoGen otimizado e funcional"""
    
    def __init__(self):
        self.models_path = Path.home() / ".cache" / "models"
        self.config = self._create_config()
        self.agents = {}
        
    def _create_config(self) -> list:
        """Cria configura√ß√£o para modelos locais"""
        config_list = []
        
        # Configura√ß√£o para LM Studio (porta padr√£o 1234)
        lm_studio_config = {
            "model": "local-model",
            "base_url": "http://localhost:1234/v1",
            "api_key": "not-needed",
            "api_type": "open_ai"
        }
        
        # Configura√ß√£o para Ollama (porta padr√£o 11434)
        ollama_config = {
            "model": "mistral",
            "base_url": "http://localhost:11434/v1",
            "api_key": "not-needed",
            "api_type": "open_ai"
        }
        
        # Configura√ß√£o para API OpenAI (se tiver chave)
        openai_key = os.getenv("OPENAI_API_KEY")
        if openai_key:
            openai_config = {
                "model": "gpt-3.5-turbo",
                "api_key": openai_key
            }
            config_list.append(openai_config)
            logger.info("‚úÖ OpenAI API configurada")
        
        # Adiciona configura√ß√µes locais
        config_list.extend([lm_studio_config, ollama_config])
        
        return config_list
    
    def setup_agents(self):
        """Configura os agentes do AutoGen"""
        
        # Configura√ß√£o LLM
        llm_config = {
            "config_list": self.config,
            "temperature": 0.7,
            "timeout": 120,
            "cache_seed": None  # Desabilita cache para testes
        }
        
        # Assistente AI
        self.agents["assistant"] = AssistantAgent(
            name="assistant",
            llm_config=llm_config,
            system_message="""Voc√™ √© um assistente AI √∫til e inteligente.
            Responda de forma clara, concisa e precisa.
            Se n√£o souber algo, diga honestamente."""
        )
        
        # Proxy do usu√°rio
        self.agents["user"] = UserProxyAgent(
            name="user",
            human_input_mode="NEVER",  # Modo autom√°tico
            max_consecutive_auto_reply=0,
            code_execution_config=False  # Desabilita execu√ß√£o de c√≥digo por seguran√ßa
        )
        
        logger.info("‚úÖ Agentes configurados com sucesso!")
    
    def chat(self, message: str):
        """Inicia uma conversa com o assistente"""
        try:
            logger.info(f"üí¨ Enviando mensagem: {message[:50]}...")
            
            # Inicia a conversa
            self.agents["user"].initiate_chat(
                self.agents["assistant"],
                message=message
            )
            
            logger.info("‚úÖ Conversa conclu√≠da!")
            
        except Exception as e:
            logger.error(f"‚ùå Erro durante conversa: {e}")
            
    def test_connection(self):
        """Testa conex√£o com os modelos"""
        logger.info("üîç Testando conex√µes...")
        
        test_message = "Responda apenas 'OK' se voc√™ est√° funcionando."
        
        for i, config in enumerate(self.config):
            logger.info(f"Testando config {i+1}: {config.get('base_url', 'OpenAI API')}")
            
            try:
                # Cria agente tempor√°rio para teste
                test_agent = AssistantAgent(
                    name=f"test_agent_{i}",
                    llm_config={
                        "config_list": [config],
                        "timeout": 30
                    }
                )
                
                # Tenta gerar resposta
                response = test_agent.generate_reply(
                    messages=[{"role": "user", "content": test_message}]
                )
                
                if response:
                    logger.info(f"‚úÖ Config {i+1} funcionando!")
                else:
                    logger.warning(f"‚ö†Ô∏è Config {i+1} sem resposta")
                    
            except Exception as e:
                logger.error(f"‚ùå Config {i+1} falhou: {e}")

def main():
    """Fun√ß√£o principal"""
    parser = argparse.ArgumentParser(description="Sistema AutoGen 1000")
    parser.add_argument("--test", action="store_true", help="Testa conex√µes")
    parser.add_argument("--chat", type=str, help="Inicia chat com mensagem")
    parser.add_argument("--interactive", action="store_true", help="Modo interativo")
    
    args = parser.parse_args()
    
    # Cria sistema
    logger.info("üöÄ Iniciando Sistema AutoGen 1000...")
    system = AutoGenSystem1000()
    system.setup_agents()
    
    # Executa a√ß√£o solicitada
    if args.test:
        system.test_connection()
    elif args.chat:
        system.chat(args.chat)
    elif args.interactive:
        logger.info("üí¨ Modo interativo. Digite 'sair' para encerrar.")
        while True:
            try:
                message = input("\nüë§ Voc√™: ")
                if message.lower() in ['sair', 'exit', 'quit']:
                    break
                system.chat(message)
            except KeyboardInterrupt:
                break
        logger.info("üëã Encerrando...")
    else:
        # Teste padr√£o
        system.chat("Ol√°! Me explique em 2 linhas o que √© intelig√™ncia artificial.")

if __name__ == "__main__":
    main()